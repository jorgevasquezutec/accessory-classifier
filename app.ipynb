{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import pyheif\n",
    "import os\n",
    "import os.path\n",
    "import math\n",
    "from sklearn import neighbors\n",
    "import pickle\n",
    "import numpy as np\n",
    "from torchvision.utils import save_image\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_fetures_mask(image_paht):\n",
    "    \n",
    "    img = Image.open(image_paht).convert('RGB')\n",
    "\n",
    "    # Definir las transformaciones necesarias para el modelo\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        # transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    img = transform(img).unsqueeze(0)\n",
    "\n",
    "# Cargar el modelo pre-entrenado de Mask R-CNN\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "    model.eval()\n",
    "\n",
    "    # Pasar la imagen por el modelo y obtener las características del objeto detectado\n",
    "    with torch.no_grad():\n",
    "        predictions = model(img)\n",
    "        # print(predictions)\n",
    "        if len(predictions[0]['boxes']) == 0:\n",
    "            # No se detectaron objetos en la imagen\n",
    "            return None\n",
    "        features = predictions[0]\n",
    "        print(features)\n",
    "\n",
    "    # print(features)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_features(image_path):\n",
    "    # Cargar la imagen\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "\n",
    "    # Definir las transformaciones necesarias para el modelo\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        # transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    img_transformed = transform(img)\n",
    "    save_image(img_transformed, 'transformed_image.jpg')\n",
    "    # Aplicar las transformaciones y agregar una dimensión adicional (batch_size=1)\n",
    "    img = transform(img).unsqueeze(0)\n",
    "\n",
    "    # Pasar la imagen por el modelo y obtener el vector característico\n",
    "    features = resnet(img)\n",
    "    features = features.detach().numpy()[0]\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converHEICtoJPEG(image_path , output):\n",
    "    with open(image_path, 'rb') as f:\n",
    "        img = pyheif.read(f)\n",
    "\n",
    "    # Convierte la imagen HEIC a RGB\n",
    "    rgb_image = Image.frombytes(\n",
    "        img.mode, \n",
    "        img.size, \n",
    "        img.data,\n",
    "        \"raw\",\n",
    "        img.mode,\n",
    "        img.stride,\n",
    "    )\n",
    "    # Guarda la imagen RGB en formato JPEG\n",
    "    rgb_image.save(output, format='JPEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dir, model_save_path=None,  n_neighbors=None, knn_algo='ball_tree', verbose=False):\n",
    "    X = []\n",
    "    y = []\n",
    "    for class_dir in os.listdir(train_dir):\n",
    "        if not os.path.isdir(os.path.join(train_dir, class_dir)):\n",
    "            continue\n",
    "\n",
    "        for img_file in os.listdir(os.path.join(train_dir, class_dir)):\n",
    "            # Obtener el path completo de la imagen\n",
    "            img_path = os.path.join(train_dir, class_dir, img_file)\n",
    "\n",
    "            # Extraer el vector característico de la imagen\n",
    "            features = get_image_features(img_path)\n",
    "            features = features.reshape(1, -1)\n",
    "            # Agregar el vector característico y la etiqueta al conjunto de datos\n",
    "            X.append(features[0])\n",
    "            y.append(class_dir)\n",
    "\n",
    "    if n_neighbors is None:\n",
    "        n_neighbors = int(round(math.sqrt(len(X))))\n",
    "        if verbose:\n",
    "            print(\"Chose n_neighbors automatically:\", n_neighbors)\n",
    "\n",
    "    # Create and train the KNN classifier\n",
    "    knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights='distance')\n",
    "    knn_clf.fit(X, y)\n",
    "\n",
    "    # Save the trained KNN classifier\n",
    "    if model_save_path is not None:\n",
    "        with open(model_save_path, 'wb') as f:\n",
    "            pickle.dump(knn_clf, f)\n",
    "\n",
    "    return knn_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_img_path, knn_clf=None, model_path=None, distance_threshold=0.6):\n",
    "    if not os.path.isfile(X_img_path) or os.path.splitext(X_img_path)[1][1:] not in ALLOWED_EXTENSIONS:\n",
    "        raise Exception(\"Invalid image path: {}\".format(X_img_path))\n",
    "    if knn_clf is None and model_path is None:\n",
    "        raise Exception(\"Must supply knn classifier either thourgh knn_clf or model_path\")\n",
    "    \n",
    "    if knn_clf is None:\n",
    "        with open(model_path, 'rb') as f:\n",
    "            knn_clf = pickle.load(f)\n",
    "\n",
    "    X_img = get_image_features(X_img_path)\n",
    "    X_img = X_img.reshape(1, -1)\n",
    "    closest_distances = knn_clf.kneighbors(X_img, n_neighbors=3)\n",
    "    print(closest_distances)\n",
    "    are_matches = closest_distances[0][0][0] <= distance_threshold\n",
    "    predit = knn_clf.predict(X_img)\n",
    "    print(predit)\n",
    "    # print(closest_distances)\n",
    "    # print(closest_distances[0][0][0])\n",
    "    # print(closest_distances)\n",
    "    # predit = knn_clf.predict(X_img)\n",
    "    # print(predit)\n",
    "    # are_matches = closest_distances[0][0][0] <= distance_threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNN classifier...\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"Training KNN classifier...\")\n",
    "classifier = train(\"data/train\", model_save_path=\"trained_knn_model.clf\", n_neighbors=2)\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# Test the model and check the accuracy of KNN classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[3.09587466, 3.10638987, 3.16593791]]), array([[1, 0, 2]]))\n",
      "['Schwartz_Jodi 3.21.23_lgorbitvu_21_BATCHED']\n"
     ]
    }
   ],
   "source": [
    "predict(\"data/test/image1.jpg\", model_path=\"trained_knn_model.clf\", distance_threshold=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "converHEICtoJPEG(\"Dataset/Ensembles/IMG_5482.HEIC\", \"data/test/image2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[2.82101575, 2.87046412, 2.90322464]]), array([[1, 2, 3]]))\n",
      "['Schwartz_Jodi 3.21.23_lgorbitvu_21_BATCHED']\n"
     ]
    }
   ],
   "source": [
    "predict(\"data/test/image2.jpg\", model_path=\"trained_knn_model.clf\", distance_threshold=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "converHEICtoJPEG(\"Dataset/Sneakers/IMG_5459.HEIC\", \"data/test/image3.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0.        , 2.96609496, 3.19797174]]), array([[5, 3, 2]]))\n",
      "['Berchtold_Marvelle 3.20.23 Rack 2.1_lgorbitvu_7_BATCHED']\n"
     ]
    }
   ],
   "source": [
    "predict(\"data/test/image4.jpg\", model_path=\"trained_knn_model.clf\", distance_threshold=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'maskrcnn_bbox_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/jorge/Documentos/local/proyectos/products-similarity/app.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jorge/Documentos/local/proyectos/products-similarity/app.ipynb#X41sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m get_image_fetures_mask(\u001b[39m\"\u001b[39;49m\u001b[39mdata/test/image1.jpg\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32m/home/jorge/Documentos/local/proyectos/products-similarity/app.ipynb Cell 15\u001b[0m in \u001b[0;36mget_image_fetures_mask\u001b[0;34m(image_paht)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jorge/Documentos/local/proyectos/products-similarity/app.ipynb#X41sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(predictions[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mboxes\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jorge/Documentos/local/proyectos/products-similarity/app.ipynb#X41sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39m# No se detectaron objetos en la imagen\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jorge/Documentos/local/proyectos/products-similarity/app.ipynb#X41sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/jorge/Documentos/local/proyectos/products-similarity/app.ipynb#X41sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m features \u001b[39m=\u001b[39m predictions[\u001b[39m0\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mmaskrcnn_bbox_features\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jorge/Documentos/local/proyectos/products-similarity/app.ipynb#X41sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mprint\u001b[39m(features)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'maskrcnn_bbox_features'"
     ]
    }
   ],
   "source": [
    "get_image_fetures_mask(\"data/test/image1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jorge/.cache/torch/hub\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.hub.get_dir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import torch\n",
    "\n",
    "cache_dir = torch.hub.get_dir()\n",
    "shutil.rmtree(cache_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
